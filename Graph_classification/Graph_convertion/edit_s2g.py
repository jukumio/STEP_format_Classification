import os
import argparse
from .Parser.Make_graph import make_graph_simplex_direct


def validate_step_file(file_path):
    """
    STEP íŒŒì¼ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ê³  ê¸°ë³¸ ì •ë³´ë¥¼ ì¶œë ¥
    """
    if not os.path.exists(file_path):
        return False, "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
    
    if not os.path.isfile(file_path):
        return False, "ë””ë ‰í† ë¦¬ì…ë‹ˆë‹¤, íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤"
    
    file_size = os.path.getsize(file_path)
    if file_size == 0:
        return False, "íŒŒì¼ í¬ê¸°ê°€ 0ì…ë‹ˆë‹¤"
    
    # íŒŒì¼ ì½ê¸° ê¶Œí•œ í™•ì¸
    if not os.access(file_path, os.R_OK):
        return False, "íŒŒì¼ ì½ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤"
    
    # STEP íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ ëª‡ ì¤„)
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            first_lines = []
            for i in range(5):  # ì²˜ìŒ 5ì¤„ë§Œ ì½ê¸°
                line = f.readline().strip()
                if not line:
                    break
                first_lines.append(line)
        
        # STEP íŒŒì¼ì˜ ê¸°ë³¸ í—¤ë” í™•ì¸
        has_iso_header = any('ISO-10303' in line for line in first_lines)
        has_step_header = any(line.startswith('ISO-10303') for line in first_lines)
        
        info = {
            'size': file_size,
            'first_lines': first_lines,
            'has_iso_header': has_iso_header,
            'has_step_header': has_step_header
        }
        
        return True, info
        
    except Exception as e:
        return False, f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}"


def analyze_class_structure(class_path, debug=False):
    """
    í´ë˜ìŠ¤ ë””ë ‰í† ë¦¬ì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•´ì„œ ì²˜ë¦¬ ë°©ë²• ê²°ì •
    Returns: ('direct', step_files) or ('splits', split_dirs)
    """
    if debug:
        print(f"    Analyzing structure of: {class_path}")
    
    try:
        items = os.listdir(class_path)
    except Exception as e:
        if debug:
            print(f"    Error reading directory: {e}")
        return 'error', str(e)
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ STEP íŒŒì¼ë“¤
    step_files = [f for f in items if f.lower().endswith(('.stp', '.step'))]
    
    # í•˜ìœ„ ë””ë ‰í† ë¦¬ë“¤
    subdirs = [d for d in items if os.path.isdir(os.path.join(class_path, d))]
    
    # í•˜ìœ„ ë””ë ‰í† ë¦¬ì— STEP íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    subdirs_with_steps = []
    for subdir in subdirs:
        subdir_path = os.path.join(class_path, subdir)
        try:
            subdir_files = os.listdir(subdir_path)
            subdir_steps = [f for f in subdir_files if f.lower().endswith(('.stp', '.step'))]
            if subdir_steps:
                subdirs_with_steps.append({
                    'name': subdir,
                    'path': subdir_path,
                    'step_files': subdir_steps
                })
        except Exception as e:
            if debug:
                print(f"    Error reading subdirectory {subdir}: {e}")
            continue
    
    if debug:
        print(f"    Direct STEP files: {len(step_files)}")
        print(f"    Subdirectories with STEP files: {len(subdirs_with_steps)}")
        if subdirs_with_steps:
            print(f"    Split directories: {[d['name'] for d in subdirs_with_steps]}")
    
    # ì²˜ë¦¬ ë°©ë²• ê²°ì •
    if subdirs_with_steps:
        # í•˜ìœ„ ë””ë ‰í† ë¦¬ì— STEP íŒŒì¼ì´ ìˆìœ¼ë©´ split êµ¬ì¡°ë¡œ ì²˜ë¦¬
        return 'splits', subdirs_with_steps
    elif step_files:
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì— STEP íŒŒì¼ì´ ìˆìœ¼ë©´ ì§ì ‘ ì²˜ë¦¬
        return 'direct', step_files
    else:
        # STEP íŒŒì¼ì´ ì—†ìŒ
        return 'empty', []


def process_class_direct(class_name, class_path, output_class_dir, path_stp, path_graph, step_files, debug=False):
    """
    í´ë˜ìŠ¤ ë””ë ‰í† ë¦¬ì— ì§ì ‘ ìˆëŠ” STEP íŒŒì¼ë“¤ì„ ì²˜ë¦¬
    """
    if debug:
        print(f"  Processing class '{class_name}' with direct STEP files")
    
    successful = 0
    failed = 0
    
    for i, file in enumerate(step_files, 1):
        print(f"    Processing {i}/{len(step_files)}: {file}")
        
        full_file_path = os.path.join(class_path, file)
        
        if debug:
            print(f"      Full file path: {full_file_path}")
            
            # íŒŒì¼ ê²€ì¦
            is_valid, validation_info = validate_step_file(full_file_path)
            if not is_valid:
                print(f"      âŒ File validation failed: {validation_info}")
                failed += 1
                continue
            else:
                print(f"      âœ“ File is valid (size: {validation_info['size']} bytes)")
        
        try:
            # make_graph_simplex_direct í•¨ìˆ˜ í˜¸ì¶œ
            rel_file_path = f"{class_name}/{file}"
            
            if debug:
                print(f"      Calling make_graph_simplex_direct with:")
                print(f"        - file_name: {rel_file_path}")
                print(f"        - graph_saves_base_paths: {path_graph}")
                print(f"        - dataset_path: {path_stp}")
            
            g = make_graph_simplex_direct(
                file_name=rel_file_path,
                graph_saves_base_paths=path_graph,
                dataset_path=path_stp
            )
            
            if g is not None:
                successful += 1
                print(f"      âœ… Successfully converted: {file}")
                if debug and hasattr(g, 'number_of_nodes'):
                    print(f"        - Graph nodes: {g.number_of_nodes()}")
                    print(f"        - Graph edges: {g.number_of_edges()}")
            else:
                failed += 1
                print(f"      âš ï¸  Warning: make_graph_simplex_direct returned None for {file}")
                
                # ì¶”ê°€ ë””ë²„ê¹…: ì˜ˆìƒ ì¶œë ¥ íŒŒì¼ í™•ì¸
                if debug:
                    expected_output = os.path.join(output_class_dir, file.rsplit('.', 1)[0] + '.graphml')
                    if os.path.exists(expected_output):
                        output_size = os.path.getsize(expected_output)
                        print(f"        - Output file exists: {expected_output}")
                        print(f"        - Output file size: {output_size} bytes")
                    else:
                        print(f"        - Expected output file not found: {expected_output}")
                
        except Exception as e:
            failed += 1
            print(f"      âŒ Error processing {file}: {str(e)}")
            if debug:
                import traceback
                print(f"      Full traceback: {traceback.format_exc()}")
            continue
    
    return successful, failed


def process_class_with_splits(class_name, class_path, output_class_dir, path_stp, path_graph, split_info, debug=False):
    """
    í´ë˜ìŠ¤ ë””ë ‰í† ë¦¬ì˜ split êµ¬ì¡° ì²˜ë¦¬ (train/valid/test ë“±)
    """
    if debug:
        print(f"  Processing class '{class_name}' with split directories")
    
    successful = 0
    failed = 0
    
    for split_data in split_info:
        split_name = split_data['name']
        split_path = split_data['path']
        step_files = split_data['step_files']
        
        print(f"\n    Processing split: {split_name}")
        
        # Create output split directory
        output_split_dir = os.path.join(output_class_dir, split_name)
        if not os.path.exists(output_split_dir):
            os.makedirs(output_split_dir)
        
        print(f"      Found {len(step_files)} STEP files")
        
        for i, file in enumerate(step_files, 1):
            print(f"      Processing {i}/{len(step_files)}: {file}")
            
            full_file_path = os.path.join(split_path, file)
            
            if debug:
                print(f"        Full file path: {full_file_path}")
                
                # íŒŒì¼ ê²€ì¦
                is_valid, validation_info = validate_step_file(full_file_path)
                if not is_valid:
                    print(f"        âŒ File validation failed: {validation_info}")
                    failed += 1
                    continue
                else:
                    print(f"        âœ“ File is valid (size: {validation_info['size']} bytes)")
            
            try:
                # Construct relative path for make_graph function
                rel_file_path = f"{class_name}/{split_name}/{file}"
                
                if debug:
                    print(f"        Calling make_graph_simplex_direct with:")
                    print(f"          - file_name: {rel_file_path}")
                    print(f"          - graph_saves_base_paths: {path_graph}")
                    print(f"          - dataset_path: {path_stp}")
                
                # Call the graph generation function
                g = make_graph_simplex_direct(
                    file_name=rel_file_path,
                    graph_saves_base_paths=path_graph,
                    dataset_path=path_stp
                )
                
                if g is not None:
                    successful += 1
                    print(f"        âœ… Successfully converted: {file}")
                    if debug and hasattr(g, 'number_of_nodes'):
                        print(f"          - Graph nodes: {g.number_of_nodes()}")
                        print(f"          - Graph edges: {g.number_of_edges()}")
                else:
                    failed += 1
                    print(f"        âš ï¸  Warning: make_graph_simplex_direct returned None for {file}")
                    
                    # ì¶”ê°€ ë””ë²„ê¹…: ì˜ˆìƒ ì¶œë ¥ íŒŒì¼ í™•ì¸
                    if debug:
                        expected_output = os.path.join(output_split_dir, file.rsplit('.', 1)[0] + '.graphml')
                        if os.path.exists(expected_output):
                            output_size = os.path.getsize(expected_output)
                            print(f"          - Output file exists: {expected_output}")
                            print(f"          - Output file size: {output_size} bytes")
                        else:
                            print(f"          - Expected output file not found: {expected_output}")
                    
            except Exception as e:
                failed += 1
                print(f"        âŒ Error processing {file}: {str(e)}")
                if debug:
                    import traceback
                    print(f"        Full traceback: {traceback.format_exc()}")
                continue
    
    return successful, failed


def make_graphh_dataset_adaptive(path_stp, path_graph, debug=True):
    """
    ì ì‘í˜• STEP to Graph ë³€í™˜ê¸°
    - í´ë˜ìŠ¤ë³„ë¡œ êµ¬ì¡°ë¥¼ ìë™ ê°ì§€
    - Split ë””ë ‰í† ë¦¬ê°€ ìˆìœ¼ë©´ split ì²˜ë¦¬
    - ì—†ìœ¼ë©´ ì§ì ‘ íŒŒì¼ ì²˜ë¦¬
    """
    if not path_stp.endswith("/"):
        path_stp = path_stp + "/"
    if not path_graph.endswith("/"):
        path_graph = path_graph + "/"

    if not os.path.exists(path_graph):
        os.makedirs(path_graph)
    
    print(f"ğŸš€ Starting adaptive STEP to GraphML conversion")
    print(f"ğŸ“ Source directory: {path_stp}")
    print(f"ğŸ’¾ Output directory: {path_graph}")
    print(f"ğŸ› Debug mode: {debug}")
    
    # Get all class directories
    try:
        class_dirs = [d for d in os.listdir(path_stp) 
                      if os.path.isdir(os.path.join(path_stp, d))]
    except Exception as e:
        print(f"âŒ Error reading source directory: {e}")
        return
    
    if not class_dirs:
        print(f"âŒ No class directories found in {path_stp}")
        return
    
    print(f"ğŸ“‚ Found {len(class_dirs)} class directories: {class_dirs}")
    
    total_files = 0
    successful_conversions = 0
    failed_conversions = 0
    
    # ê° í´ë˜ìŠ¤ë³„ ì²˜ë¦¬ ë°©ë²• ìš”ì•½
    processing_summary = []
    
    for class_dir in class_dirs:
        print(f"\n{'='*50}")
        print(f"ğŸ·ï¸  Processing class: {class_dir}")
        print(f"{'='*50}")
        
        class_path = os.path.join(path_stp, class_dir)
        
        # Create output class directory
        output_class_dir = os.path.join(path_graph, class_dir)
        if not os.path.exists(output_class_dir):
            os.makedirs(output_class_dir)
        
        # í´ë˜ìŠ¤ êµ¬ì¡° ë¶„ì„
        structure_type, structure_data = analyze_class_structure(class_path, debug)
        
        if structure_type == 'error':
            print(f"  âŒ Error analyzing class structure: {structure_data}")
            processing_summary.append({
                'class': class_dir,
                'type': 'error',
                'files': 0,
                'successful': 0,
                'failed': 0
            })
            continue
        elif structure_type == 'empty':
            print(f"  âš ï¸  No STEP files found in class '{class_dir}'")
            processing_summary.append({
                'class': class_dir,
                'type': 'empty',
                'files': 0,
                'successful': 0,
                'failed': 0
            })
            continue
        
        # íŒŒì¼ ê°œìˆ˜ ê³„ì‚°
        if structure_type == 'direct':
            file_count = len(structure_data)
        else:  # splits
            file_count = sum(len(split_data['step_files']) for split_data in structure_data)
        
        total_files += file_count
        print(f"  ğŸ“Š Structure type: {structure_type}")
        print(f"  ğŸ“ˆ Total STEP files: {file_count}")
        
        # ì ì ˆí•œ ì²˜ë¦¬ ë°©ë²• ì„ íƒ
        if structure_type == 'direct':
            successful, failed = process_class_direct(
                class_dir, class_path, output_class_dir, path_stp, path_graph, structure_data, debug
            )
        else:  # splits
            successful, failed = process_class_with_splits(
                class_dir, class_path, output_class_dir, path_stp, path_graph, structure_data, debug
            )
        
        successful_conversions += successful
        failed_conversions += failed
        
        processing_summary.append({
            'class': class_dir,
            'type': structure_type,
            'files': file_count,
            'successful': successful,
            'failed': failed
        })
        
        print(f"  âœ… Class '{class_dir}' completed: {successful}/{file_count} successful")
    
    # ìµœì¢… ìš”ì•½
    print(f"\n{'='*60}")
    print("ğŸ¯ FINAL CONVERSION SUMMARY")
    print(f"{'='*60}")
    
    print(f"\nğŸ“‹ Processing Details by Class:")
    for summary in processing_summary:
        if summary['type'] == 'error':
            print(f"  âŒ {summary['class']}: Error in processing")
        elif summary['type'] == 'empty':
            print(f"  âšª {summary['class']}: No STEP files found")
        else:
            success_rate = (summary['successful']/summary['files']*100) if summary['files'] > 0 else 0
            print(f"  ğŸ“Š {summary['class']}: {summary['successful']}/{summary['files']} files ({success_rate:.1f}%) - {summary['type']} structure")
    
    print(f"\nğŸ† Overall Statistics:")
    print(f"  ğŸ“ Total classes processed: {len(class_dirs)}")
    print(f"  ğŸ“„ Total STEP files found: {total_files}")
    print(f"  âœ… Successfully converted: {successful_conversions}")
    print(f"  âŒ Failed conversions: {failed_conversions}")
    
    if total_files > 0:
        success_rate = (successful_conversions/total_files*100)
        print(f"  ğŸ“ˆ Overall success rate: {success_rate:.1f}%")
    
    print(f"\nğŸ‰ Conversion completed!")


def make_graphh_dataset(path_stp, path_graph, debug=True):
    """
    ê¸°ì¡´ ì¬ê·€ ì²˜ë¦¬ í•¨ìˆ˜ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
    """
    print("âš ï¸  Using legacy recursive mode. Consider using 'adaptive' mode for better results.")
    return make_graphh_dataset_adaptive(path_stp, path_graph, debug)


def make_graphh_dataset_class_structure(path_stp, path_graph, debug=True):
    """
    ê¸°ì¡´ í´ë˜ìŠ¤ êµ¬ì¡° í•¨ìˆ˜ (í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€)
    """
    print("âš ï¸  Using legacy class_structure mode. Consider using 'adaptive' mode for better results.")
    return make_graphh_dataset_adaptive(path_stp, path_graph, debug)


def debug_make_graph_function(file_path, graph_path, dataset_path):
    """
    make_graph_simplex_direct í•¨ìˆ˜ë¥¼ ì§ì ‘ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë””ë²„ê¹… í•¨ìˆ˜
    """
    print(f"\n=== DEBUGGING make_graph_simplex_direct ===")
    print(f"Input parameters:")
    print(f"  file_name: {file_path}")
    print(f"  graph_saves_base_paths: {graph_path}")
    print(f"  dataset_path: {dataset_path}")
    
    # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ í™•ì¸
    full_path = os.path.join(dataset_path, file_path)
    print(f"  Computed full path: {full_path}")
    print(f"  File exists: {os.path.exists(full_path)}")
    
    if os.path.exists(full_path):
        print(f"  File size: {os.path.getsize(full_path)} bytes")
        
        # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
        try:
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                first_line = f.readline().strip()
                print(f"  First line: {first_line}")
        except Exception as e:
            print(f"  Error reading file: {e}")
    
    # make_graph_simplex_direct í•¨ìˆ˜ í˜¸ì¶œ
    try:
        result = make_graph_simplex_direct(
            file_name=file_path,
            graph_saves_base_paths=graph_path,
            dataset_path=dataset_path
        )
        print(f"  Function result: {result}")
        print(f"  Result type: {type(result)}")
        
        if result is not None and hasattr(result, 'number_of_nodes'):
            print(f"  Graph nodes: {result.number_of_nodes()}")
            print(f"  Graph edges: {result.number_of_edges()}")
            
        return result
        
    except Exception as e:
        print(f"  Exception occurred: {str(e)}")
        import traceback
        print(f"  Full traceback: {traceback.format_exc()}")
        return None


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Convert STEP files to graphs - Adaptive version")
    parser.add_argument("--path_step", required=True, help="Path to STEP files directory")
    parser.add_argument("--path_graph", required=True, help="Path to save graph files")
    parser.add_argument("--mode", choices=['adaptive', 'recursive', 'class_structure', 'debug'], 
                       default='adaptive',
                       help="Processing mode: 'adaptive' (recommended) automatically detects structure, "
                            "'recursive' for general recursive processing, "
                            "'class_structure' for class/train-valid-test structure, "
                            "'debug' for single file debugging")
    parser.add_argument("--debug", action='store_true', help="Enable debug output")
    parser.add_argument("--test_file", help="Single file to test (for debug mode)")
    
    args = parser.parse_args()

    path_stp = args.path_step
    path_graph = args.path_graph
    mode = args.mode
    debug = args.debug

    print(f"ğŸš€ Starting conversion in '{mode}' mode...")
    
    if mode == 'adaptive':
        make_graphh_dataset_adaptive(path_stp, path_graph, debug)
    elif mode == 'recursive':
        make_graphh_dataset(path_stp, path_graph, debug)
    elif mode == 'class_structure':
        make_graphh_dataset_class_structure(path_stp, path_graph, debug)
    elif mode == 'debug':
        if args.test_file:
            debug_make_graph_function(args.test_file, path_graph, path_stp)
        else:
            print("Debug mode requires --test_file parameter")